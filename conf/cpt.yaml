defaults: # inherit parameter values (Hydra inheritance syntax/functionality)
  - common
  - _self_

data:
  train:
    dataset:
      source: anilkeshwani/mls-hubert_large_ll60k-layer_22
      split: train
      sequence_type: interleaved
      interleave_kwargs:
        sampling_rate: 16000 # sampling rate of audio input data to HuBERT ("model sampling rate")
        downsampling_ratio: 320 # downsampling ratio for HuBERT i.e. 320 samples -> 1 token
        mean_seq_len_tokens: 39.43 # mean sequence length in tokens of the MLS en trainset stratified sample (25%)
        binom_prob: 0.1 # fraction of sequence to make up subspans -> recall: binomial expectation = np
      deduplicate: ${speech.deduplicate}
      use_modality_tokens: ${speech.use_modality_tokens}
      add_eos: True
    dataloader:
      batch_size: 16
      drop_last: True
    shuffle: True
    packed: False # TODO packing performed a priori at training time and leads to CPU RAM overflow for e.g. MLS interleaved
  dev:
    dataset:
      source: anilkeshwani/mls-hubert_large_ll60k-layer_22
      split: validation
      sequence_type: interleaved
      interleave_kwargs:
        sampling_rate: 16000 # sampling rate of audio input data to HuBERT ("model sampling rate")
        downsampling_ratio: 320 # downsampling ratio for HuBERT i.e. 320 samples -> 1 token
        mean_seq_len_tokens: 39.43 # mean sequence length in tokens of the MLS en trainset stratified sample (25%)
        binom_prob: 0.1 # fraction of sequence to make up subspans -> recall: binomial expectation = np
      deduplicate: ${speech.deduplicate}
      use_modality_tokens: ${speech.use_modality_tokens}
      add_eos: True
    dataloader:
      batch_size: 16
      drop_last: False
    shuffle: False
    packed: False
