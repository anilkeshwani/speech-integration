# Experiment management
model_name: Llama-3.2-1B-5000-dsus
output_dir: ${experiments_root_dir}/${model_name}
extended_models_dir: /mnt/scratch-artemis/anilkeshwani/models/extended/torchtune/
experiments_root_dir: /mnt/scratch-artemis/anilkeshwani/experiments
experiment_name: null # if null, set to W&B run name

n_dsus: 5000

# Tokenizer - config for setup_llama3_tokenizer -> Llama3Tokenizer
tokenizer:
  path: ${extended_models_dir}/${model_name}/original/tokenizer.model
  max_seq_len: null # NOTE max seq. length 128_000_000 returned by `llama model describe -m Llama3.2-1B`
  prompt_template: null
  verbose: True

# Data: NOTE Arguments to setup_data, not SFTDataset
data:
  train:
    # SFTDataset
    source: anilkeshwani/MLS_english_train_strat_sample_aligned_hubert
    # model_tokenizer taken from code
    inference: False # False for training, False for validation loss, toggled to True in code for validation inference
    filter_fn: null
    train_on_input: True # set to true to prevent forgetting; will hyperparam. search over this
    column_map:
      input: speech_tokens
      output: transcript
    new_system_prompt: "You will act as an automatic speech recognition (ASR) system. Transcribe the speech tokens into English text."
    image_dir: null

    # SFTDataset kwargs passed to datasets.load_dataset
    split: train

    # not arguments to SFT dataset:
    batch_size: 4 # passed to DataLoader
    shuffle: True # passed to DistributedSampler
    packed: False # passed to pack_dataset to create a PackedDataset
  dev:
    # SFTDataset
    source: anilkeshwani/MLS_english_train_strat_sample_aligned_hubert
    # model_tokenizer taken from code
    inference: False # False for training, False for validation loss, toggled to True in code for validation inference
    filter_fn: null
    train_on_input: True # set to true to prevent forgetting; will hyperparam. search over this
    column_map:
      input: speech_tokens
      output: transcript
    new_system_prompt: "You will act as an automatic speech recognition (ASR) system. Transcribe the speech tokens into English text."
    image_dir: null

    # SFTDataset kwargs passed to datasets.load_dataset
    split: dev # <- NOTE different from train

    # not arguments to SFT dataset:
    batch_size: 4 # passed to DataLoader
    shuffle: False # passed to DistributedSampler # <- NOTE different from train
    packed: False # passed to pack_dataset to create a PackedDataset

# Optimization
optimizer:
  lr: 2e-5
  betas: [0.9, 0.999]
  eps: 1e-8
  weight_decay: 0.01
  amsgrad: False
  fused: True
epochs: 5
max_steps: null # if unset, set according to the number of epochs and the number of steps per epoch
batch_size: 4 # effective batch size was 144 via bs=12 and grad. accum. 12 for TinyLlama
gradient_accumulation_steps: 16
clip_grad_norm: null

# Learning rate scheduler
lr_scheduler:
  _component_: torchtune.modules.lr_schedulers.get_cosine_schedule_with_warmup
  num_warmup_steps: 0 # The number of steps for the warmup phase.
  num_cycles: 0.5 # The number of waves in the cosine schedule. Defaults to 0.5. (decrease from the max value to 0 following a half-cosine).
  last_epoch: -1 # The index of the last epoch when resuming training. Defaults to -1. Set to self.global_step - 1 in recipe.
  # optimizer: # set dynamically in recipe
  # num_training_steps: # set to total_epochs * _steps_per_epoch (:= len(self._dataloader) // self._gradient_accumulation_steps)

# Performance optimizations
optimizer_in_bwd: False # https://pytorch.org/tutorials/intermediate/optimizer_step_in_backward_tutorial.html
compile: False # set it to True for better memory and performance
# Memory management
enable_activation_checkpointing: False # True reduces memory
enable_activation_offloading: False # True reduces memory

# Training environment
device: cuda

# Reduced precision
dtype: bf16

# Checkpointing
checkpointer:
  _component_: torchtune.training.FullModelHFCheckpointer
  checkpoint_dir: ${extended_models_dir}/${model_name}
  checkpoint_files: [hf_model_0001_0.pt]
  model_type: LLAMA3_2
  recipe_checkpoint: null
  output_dir: # if null: ${experiments_root_dir}/${model_name}/${experiment_name}/${checkpoints}; was ${output_dir}
  resume_from_checkpoint: False
  adapter_checkpoint: null
  safe_serialization: False

# Logging
metric_logger:
  _component_: torchtune.training.metric_logging.WandBLogger
  log_dir: ${output_dir}
  project: speech-integration
  entity: null # automatically set to username based on API key
  group: null

log_every_n_steps: 1
log_peak_memory_stats: False
save_steps: 500
eval_steps: ${save_steps} # evaluation

# Debug mode
# `None` -> don't set any PyTorch global values
# "default" or 0 -> don't error or warn on nondeterministic operations and additionally enable PyTorch CuDNN benchmark
# "warn" or 1 -> warn on nondeterministic operations and disable PyTorch CuDNN benchmark
# "error" or 2 -> error on nondeterministic operations and disable PyTorch CuDNN benchmark
debug_mode: null
